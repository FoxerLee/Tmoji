{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建sparkSession对象\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"myApp\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/bigdata.raw\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/bigdata.t3\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                 _id|               emoji|            sentence|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[5ea4eddb59a37f98...|      :red_heart:,18|No object is so b...|\n",
      "|[5ea4eddb59a37f98...|:person_shrugging...|Cant expect diffe...|\n",
      "|[5ea4eddb59a37f98...|:face_with_tears_...|“ Lets go Marcus ...|\n",
      "|[5ea4eddb59a37f98...|:face_with_tears_...|Asahd really is a...|\n",
      "|[5ea4eddb59a37f98...|:face_with_tears_...|Yoongi Tweet Hell...|\n",
      "|[5ea4eddb59a37f98...|:backhand_index_p...|we cannot afford ...|\n",
      "|[5ea4eddb59a37f98...|:party_popper:,8 ...|ranks 6th in Janu...|\n",
      "|[5ea4eddb59a37f98...|:person_facepalmi...|Ok people are rea...|\n",
      "|[5ea4eddb59a37f98...|:smiling_face_wit...|Cant wait to meet...|\n",
      "|[5ea4eddb59a37f98...| :clapping_hands:,11|Congratulations M...|\n",
      "|[5ea4eddb59a37f98...|:face_with_tears_...|Met orlando brown...|\n",
      "|[5ea4eddb59a37f98...|      :weary_face:,4|Im goin to bed :w...|\n",
      "|[5ea4eddb59a37f98...|  :clapping_hands:,9|Will and Jada on ...|\n",
      "|[5ea4eddb59a37f98...|:person_shrugging...|EVERYBODY is preg...|\n",
      "|[5ea4eddb59a37f98...|       :male_sign:,8|I promise to fuck...|\n",
      "|[5ea4eddb59a37f98...|    :folded_hands:,3|God keep working ...|\n",
      "|[5ea4eddb59a37f98...|    :party_popper:,4|Happy Birthday to...|\n",
      "|[5ea4eddb59a37f98...|  :hundred_points:,8|Over 3M Dollars i...|\n",
      "|[5ea4eddb59a37f98...|:loudly_crying_fa...|I be considering ...|\n",
      "|[5ea4eddb59a37f98...|:rolling_on_the_f...|My teacher gave s...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "df = df.limit(100000)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the appearance frequency of every emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji = \":red_heart:\"\n",
    "emojis = df.select('emoji')\n",
    "# emojis.show()\n",
    "def split_str(line):\n",
    "    res = []\n",
    "    \n",
    "    words = line.emoji.split(\" \")\n",
    "    for word in words:\n",
    "        tmp = word.split(',')[0]\n",
    "        res.append(tmp)\n",
    "    return \" \".join(res)\n",
    "\n",
    "emojis = emojis.rdd.map(split_str)\n",
    "emojis.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = emojis.flatMap(lambda x: x.split(\" \")) \\\n",
    "        .map(lambda x: (x, 1)) \\\n",
    "        .reduceByKey(add) \\\n",
    "        .sortBy(lambda x: x[1], ascending= False) \n",
    "#         sortBy(lambda x: x[1], False)\n",
    "# result.take(3)\n",
    "result.take(10)\n",
    "# for v, k in result:\n",
    "#     print(\"{} {}\".format(v, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['emoji', 'fre']\n",
    "result = result.toDF(*new_names)\n",
    "result = result.withColumn('fre', result['fre']/1890000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every emoji, ﬁnd the 3 other emojis that are used most frequently with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "emojis = df.select('emoji')\n",
    "\n",
    "def split_arr(line):\n",
    "    res = []\n",
    "    \n",
    "    words = line.emoji.split(\" \")\n",
    "    for word in words:\n",
    "        tmp = word.split(',')[0]\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "def combination(line):\n",
    "    combs = list(combinations(line, 2))\n",
    "    res = []\n",
    "    \n",
    "    top10 = [':face_with_tears_of_joy:', ':red_heart:',':loudly_crying_face:', ':fire:', \\\n",
    "             ':smiling_face_with_heart-eyes:', ':female_sign:', ':clapping_hands:', \\\n",
    "             ':folded_hands:', ':male_sign:', ':backhand_index_pointing_right:']\n",
    "    for comb in combs:\n",
    "        p0 = comb[0]\n",
    "        p1 = comb[1]\n",
    "        if p0 not in top10:\n",
    "            p0 = 'others'\n",
    "        if p1 not in top10:\n",
    "            p1 = 'others'\n",
    "    \n",
    "        if p0 != p1:\n",
    "            res.append((p0, p1))\n",
    "            res.append((p1, p0))\n",
    "    return res\n",
    "\n",
    "emojis_comb = emojis.rdd.map(split_arr) \\\n",
    "        .filter(lambda x: len(x) > 1) \\\n",
    "        .map(combination) \\\n",
    "        .flatMap(lambda x: x) \\\n",
    "        .map(lambda x: (x, 1)) \\\n",
    "        .reduceByKey(add) \\\n",
    "        .map(lambda x: (x[0][0], (x[0][1], x[1]))) \n",
    "\n",
    "def sort_func(x):\n",
    "    return x[1]\n",
    "\n",
    "def top_10(line):\n",
    "    candidate = tuple(list(line[1]))\n",
    "    return (line[0], candidate)\n",
    "#     sort_candidate = sorted(candidate, key=sort_func, reverse=True)\n",
    "#     res = []\n",
    "#     count = 0\n",
    "#     while count < 10 and count < len(sort_candidate):\n",
    "#         res.append(sort_candidate[count][0])\n",
    "#         count += 1\n",
    "    \n",
    "#     return (line[0], res)\n",
    "\n",
    "result = emojis_comb.groupByKey() \\\n",
    "        .map(top_10) \\\n",
    "\n",
    "result.take(1)\n",
    "\n",
    "# for v, k in result:\n",
    "#     print(\"{} {}\".format(v, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_names = ['emoji', '']\n",
    "# result = result.toDF(*new_names)\n",
    "result = result.toDF()\n",
    "result = result.selectExpr(\"_1 as emoji\", \"_2 as col\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every emoji, determine it is used more with words begin with lower case or word begin with upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(':red_heart:', 2315, 5469),\n",
       " (':person_shrugging:', 226, 2081),\n",
       " (':female_sign:', 119, 61),\n",
       " (':face_with_tears_of_joy:', 2809, 15592),\n",
       " (':backhand_index_pointing_down:', 306, 607),\n",
       " (':party_popper:', 771, 532),\n",
       " (':person_facepalming:', 231, 1627),\n",
       " (':smiling_face_with_heart-eyes:', 1216, 4118),\n",
       " (':clapping_hands:', 827, 1289),\n",
       " (':weary_face:', 322, 2248)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_case(line):\n",
    "    res = []\n",
    "    sentence = line.sentence.split(' ')\n",
    "    emojis = line.emoji.split(' ')\n",
    "    \n",
    "    for emoji in emojis:\n",
    "        e, place = emoji.split(',')\n",
    "        word = sentence[int(place)-1]\n",
    "\n",
    "        if word[0].isupper():\n",
    "            res.append((e, (1, 0)))\n",
    "        elif word[0].islower():\n",
    "            res.append((e, (0, 1)))\n",
    "        else:\n",
    "            res.append((e, (0, 0)))\n",
    "    return res\n",
    "\n",
    "\n",
    "result = df.rdd.map(check_case) \\\n",
    "        .flatMap(lambda x: x) \\\n",
    "\n",
    "upper = result.map(lambda x: (x[0], x[1][0])) \\\n",
    "                .reduceByKey(add)\n",
    "\n",
    "lower = result.map(lambda x: (x[0], x[1][1])) \\\n",
    "                .reduceByKey(add) \n",
    "\n",
    "result = upper.join(lower) \\\n",
    "                .map(lambda x: (x[0], x[1][0], x[1][1]))\n",
    "\n",
    "result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|               emoji|upper|lower|\n",
      "+--------------------+-----+-----+\n",
      "|         :red_heart:| 2315| 5469|\n",
      "|  :person_shrugging:|  226| 2081|\n",
      "|       :female_sign:|  119|   61|\n",
      "|:face_with_tears_...| 2809|15592|\n",
      "|:backhand_index_p...|  306|  607|\n",
      "|      :party_popper:|  771|  532|\n",
      "|:person_facepalming:|  231| 1627|\n",
      "|:smiling_face_wit...| 1216| 4118|\n",
      "|    :clapping_hands:|  827| 1289|\n",
      "|        :weary_face:|  322| 2248|\n",
      "|         :male_sign:|  121|   47|\n",
      "|:loudly_crying_face:| 1399| 5868|\n",
      "|      :folded_hands:|  734| 1977|\n",
      "|    :hundred_points:|  464| 1246|\n",
      "|:rolling_on_the_f...|  257| 1369|\n",
      "|     :flexed_biceps:|  336|  925|\n",
      "|:backhand_index_p...| 1039| 1051|\n",
      "|       :crying_face:|  154|  701|\n",
      "|      :purple_heart:|  388|  966|\n",
      "|      :yellow_heart:|  183|  509|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = result.toDF()\n",
    "result = result.selectExpr(\"_1 as emoji\", \"_2 as upper\", \"_3 as lower\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the average of the number of emoji used in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = df.select('emoji')\n",
    "def cal_count(line):\n",
    "    res = 0\n",
    "    \n",
    "    words = line.emoji.split(\" \")\n",
    "    for word in words:\n",
    "        res += 1\n",
    "    return res\n",
    "\n",
    "emojis_count = emojis.rdd.map(cal_count)\n",
    "emojis_mapped = emojis_count.map(lambda x: (x, 1))\n",
    "total_count = emojis_mapped.reduceByKey(add).sortByKey()\n",
    "total_count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = total_count.toDF()\n",
    "result = result.selectExpr(\"_1 as num\", \"_2 as counts\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every emoji, ﬁnd the position (head, middle, end) that the emoji occurs most in a sentence.\n",
    "\n",
    "0 - head, 1 - middle, 2 - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(line):\n",
    "    sentence = line.sentence.split(' ')\n",
    "    emojis = line.emoji.split(' ')\n",
    "    \n",
    "    sentence_length = len(sentence)\n",
    "    res = []\n",
    "    \n",
    "    for emoji in emojis:\n",
    "        e, place = emoji.split(',')\n",
    "        if int(place)/sentence_length < 1/3:\n",
    "            res.append((e, 0))\n",
    "        elif int(place)/sentence_length > 2/3:\n",
    "            res.append((e, 2))\n",
    "        else:\n",
    "            res.append((e, 1))\n",
    "    return res\n",
    "\n",
    "def sort_func(x):\n",
    "    return x[1]\n",
    "\n",
    "def most_position(line):\n",
    "    positions = list(line[1])\n",
    "    positions_sort = sorted(positions, key=sort_func, reverse=True)\n",
    "    \n",
    "    return (line[0], positions_sort[0][0])\n",
    "\n",
    "\n",
    "position = df.rdd.map(position) \\\n",
    "            .flatMap(lambda x: x) \\\n",
    "            .map(lambda x: ((x[0], x[1]), 1)) \\\n",
    "            .reduceByKey(add) \\\n",
    "            .map(lambda x: (x[0][0], (x[0][1], x[1]))) \\\n",
    "            .groupByKey() \\\n",
    "            .map(most_position)\n",
    "\n",
    "position.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = position.toDF()\n",
    "result = result.selectExpr(\"_1 as emoji\", \"_2 as pos\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the relation between the length of sentence and the number of emoji used in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_relation(line):\n",
    "    \n",
    "    sentence = line.sentence.split(' ')\n",
    "    emojis = line.emoji.split(' ')\n",
    "    \n",
    "    sentence_length = len(sentence)\n",
    "    emojis_length = len(emojis)\n",
    "    return (sentence_length, emojis_length)\n",
    "\n",
    "length = df.rdd.map(length_relation)\n",
    "length_mapped = length.map(lambda x: (x, 1))\n",
    "relation = length_mapped.reduceByKey(add).sortByKey() \\\n",
    "                        .map(lambda x: (x[0][0], x[0][1], x[1]))\n",
    "\n",
    "relation.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = relation.toDF()\n",
    "result = result.selectExpr(\"_1 as sent_len\", \"_2 as emoji_len\", \"_3 as count\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every emoji, summarize the frequency that it could be used more than once in a sentence.\n",
    "\n",
    "If the times that it used more than once, we consider it equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = df.select(\"emoji\")\n",
    "\n",
    "def split_arr(line):\n",
    "    dict_ = collections.defaultdict(int)\n",
    "    res = []\n",
    "    words = line.emoji.split(\" \")\n",
    "    for word in words:\n",
    "        tmp = word.split(',')[0]\n",
    "        dict_[tmp] += 1\n",
    "    \n",
    "    for k, v in dict_.items():\n",
    "        if v > 1:\n",
    "            res.append(k)\n",
    "    return res\n",
    "\n",
    "emojis = emojis.rdd.map(split_arr)\n",
    "emojis_filter = emojis.filter(lambda x: len(x) > 0) \\\n",
    "                .flatMap(lambda x: x) \\\n",
    "                .map(lambda x: (x, 1)) \\\n",
    "                .reduceByKey(add)\n",
    "\n",
    "emojis_filter.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = emojis_filter.toDF()\n",
    "result = result.selectExpr(\"_1 as emoji\", \"_2 as count\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every emoji, ﬁnd the average word length in the sentences that contain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_length(line):\n",
    "    res = []\n",
    "    sentence = line.sentence.split(' ')\n",
    "    sentence_length = len(sentence)\n",
    "    \n",
    "    emojis = line.emoji.split(' ')\n",
    "    for emoji in emojis:\n",
    "        tmp = emoji.split(',')[0]\n",
    "        res.append((tmp, sentence_length))\n",
    "    return res\n",
    "    \n",
    "emojis_ave = df.rdd.map(average_length) \\\n",
    "            .flatMap(lambda x: x) \\\n",
    "            .map(lambda x: (x, 1)) \\\n",
    "            .reduceByKey(add)\n",
    "\n",
    "# emojis_ave.take(3)\n",
    "\n",
    "sentences_count = emojis_ave.map(lambda x: (x[0][0], x[1])) \\\n",
    "                    .reduceByKey(add)\n",
    "\n",
    "# sentences_count.take(3)\n",
    "\n",
    "words_count = emojis_ave.map(lambda x: (x[0][0], x[0][1]*x[1])) \\\n",
    "                    .reduceByKey(add)\n",
    "# words_count.take(3)\n",
    "\n",
    "ave_result = sentences_count.join(words_count) \\\n",
    "            .map(lambda x: (x[0], round(x[1][1] / x[1][0], 0)))\n",
    "\n",
    "ave_result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ave_result.toDF()\n",
    "result = result.selectExpr(\"_1 as emoji\", \"_2 as ave_len\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
